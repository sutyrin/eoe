[
  {
    "slug": "2026-01-30-au1",
    "title": "au1",
    "date": "2026-01-30",
    "type": "audio",
    "stage": "idea",
    "thumbnailUrl": "/thumbnails/2026-01-30-au1.webp",
    "code": "import * as Tone from 'tone';\nimport GUI from 'lil-gui';\nimport {\n  createSynth,\n  createEffectsChain,\n  ensureAudioContext,\n  startTransport,\n  stopTransport,\n  getTransportPosition,\n  createSequence,\n  disposeAll\n} from '../../lib/audio/index.js';\n\n// --- State ---\nlet synth = null;\nlet effectsChain = null;\nlet sequence = null;\nlet gui = null;\nlet positionInterval = null;\nlet isPlaying = false;\n\n// --- Config ---\nlet config = {\n  synth: {\n    type: 'mono',\n    oscillator: { type: 'sine' },\n    envelope: { attack: 0.01, decay: 0.2, sustain: 0.5, release: 1.0 }\n  },\n  sequence: {\n    notes: ['C4', 'E4', 'G4', 'B4', 'C5', 'B4', 'G4', 'E4'],\n    duration: '8n',\n    interval: '8n'\n  },\n  effects: {\n    reverb: { decay: 2.5, wet: 0.3 }\n  },\n  transport: {\n    bpm: 120\n  }\n};\n\nasync function init() {\n  // Load config from JSON\n  try {\n    const response = await fetch('./config.json');\n    const saved = await response.json();\n    config = { ...config, ...saved };\n  } catch (e) {\n    console.log('No saved config, using defaults');\n  }\n\n  setupAudio();\n  setupGUI();\n  setupTransportControls();\n}\n\nfunction setupAudio() {\n  // Create effects chain\n  effectsChain = createEffectsChain(config.effects);\n  effectsChain.output.toDestination();\n\n  // Create synth and connect to effects chain\n  synth = createSynth(config.synth);\n  synth.connect(effectsChain.chain);\n\n  // Create sequence\n  sequence = createSequence(synth, config.sequence);\n}\n\nfunction setupTransportControls() {\n  const playBtn = document.getElementById('playBtn');\n  const stopBtn = document.getElementById('stopBtn');\n  const positionEl = document.getElementById('position');\n\n  playBtn.addEventListener('click', async () => {\n    await ensureAudioContext();\n\n    if (!isPlaying) {\n      sequence.start(0);\n      startTransport(config.transport.bpm);\n      isPlaying = true;\n      playBtn.classList.add('active');\n\n      // Update position display\n      positionInterval = setInterval(() => {\n        positionEl.textContent = getTransportPosition();\n      }, 100);\n    }\n  });\n\n  stopBtn.addEventListener('click', () => {\n    if (isPlaying) {\n      sequence.stop();\n      stopTransport();\n      isPlaying = false;\n      playBtn.classList.remove('active');\n\n      if (positionInterval) {\n        clearInterval(positionInterval);\n        positionInterval = null;\n      }\n      positionEl.textContent = '0:0:0';\n    }\n  });\n}\n\nfunction setupGUI() {\n  gui = new GUI({ title: 'au1 Parameters' });\n\n  // Synth controls\n  const synthFolder = gui.addFolder('Synth');\n  synthFolder.add(config.synth.oscillator, 'type', ['sine', 'triangle', 'sawtooth', 'square'])\n    .name('Oscillator')\n    .onChange(val => {\n      if (synth && synth.oscillator) synth.oscillator.type = val;\n    });\n  synthFolder.add(config.synth.envelope, 'attack', 0.001, 2).name('Attack')\n    .onChange(val => { if (synth && synth.envelope) synth.envelope.attack = val; });\n  synthFolder.add(config.synth.envelope, 'decay', 0.01, 2).name('Decay')\n    .onChange(val => { if (synth && synth.envelope) synth.envelope.decay = val; });\n  synthFolder.add(config.synth.envelope, 'sustain', 0, 1).name('Sustain')\n    .onChange(val => { if (synth && synth.envelope) synth.envelope.sustain = val; });\n  synthFolder.add(config.synth.envelope, 'release', 0.01, 5).name('Release')\n    .onChange(val => { if (synth && synth.envelope) synth.envelope.release = val; });\n\n  // Transport controls\n  const transportFolder = gui.addFolder('Transport');\n  transportFolder.add(config.transport, 'bpm', 40, 200).step(1).name('BPM')\n    .onChange(val => {\n      Tone.getTransport().bpm.value = val;\n    });\n\n  // Effects controls\n  if (config.effects.reverb) {\n    const reverbFolder = gui.addFolder('Reverb');\n    reverbFolder.add(config.effects.reverb, 'decay', 0.1, 10).name('Decay');\n    reverbFolder.add(config.effects.reverb, 'wet', 0, 1).name('Wet');\n  }\n\n  gui.onChange(() => {\n    console.log('Copy to config.json:', JSON.stringify(config, null, 2));\n  });\n}\n\n// --- Cleanup ---\nasync function cleanup() {\n  if (positionInterval) {\n    clearInterval(positionInterval);\n    positionInterval = null;\n  }\n\n  await disposeAll({\n    sequences: [sequence],\n    effects: effectsChain,\n    synths: [synth],\n    gui\n  });\n\n  synth = null;\n  effectsChain = null;\n  sequence = null;\n  gui = null;\n  isPlaying = false;\n}\n\n// Initialize\ninit();\n\n// Vite HMR cleanup (prevents audio duplication and memory leaks)\nif (import.meta.hot) {\n  import.meta.hot.dispose(async () => {\n    await cleanup();\n  });\n}\n",
    "notes": "# au1\n\n**Created:** 2026-01-30\n**Stage:** idea\n**Type:** audio\n\n## Intent\nWhat am I exploring with this audio atom? What mood or texture?\n\n## Sound Design\n- Synth type:\n- Key/scale:\n- Tempo:\n- Effects chain:\n\n## Technical Decisions\n- Why this approach?\n- What synthesis techniques?\n\n## Session Log\n\n### 2026-01-30 14:03\n- Created audio atom\n- Initial setup\n\n### 2026-01-30 11:03:53\n- \n",
    "configJson": "{\n  \"type\": \"audio\",\n  \"synth\": {\n    \"type\": \"mono\",\n    \"oscillator\": { \"type\": \"sine\" },\n    \"envelope\": {\n      \"attack\": 0.01,\n      \"decay\": 0.2,\n      \"sustain\": 0.5,\n      \"release\": 1.0\n    }\n  },\n  \"sequence\": {\n    \"notes\": [\"C4\", \"E4\", \"G4\", \"B4\", \"C5\", \"B4\", \"G4\", \"E4\"],\n    \"duration\": \"8n\",\n    \"interval\": \"8n\"\n  },\n  \"effects\": {\n    \"reverb\": {\n      \"decay\": 2.5,\n      \"wet\": 0.3\n    }\n  },\n  \"transport\": {\n    \"bpm\": 120\n  }\n}\n"
  },
  {
    "slug": "2026-01-30-av-sync-debug",
    "title": "av-sync-debug",
    "date": "2026-01-30",
    "type": "audio-visual",
    "stage": "idea",
    "thumbnailUrl": "/thumbnails/2026-01-30-av-sync-debug.webp",
    "code": "import { initAudio, startAudio, stopAudio, getAudioData, getIsPlaying, cleanupAudio } from './audio.js';\nimport config from './config.json';\n\nlet audioData = null;\nlet lastBeatTime = 0;\nlet beatFlashIntensity = 0;\n\n/**\n * p5.js setup - runs once at start\n */\nexport function setup(p) {\n  p.createCanvas(800, 800);\n  p.frameRate(60);\n\n  // Initialize audio system\n  initAudio(config);\n}\n\n/**\n * p5.js draw - runs every frame\n */\nexport function draw(p) {\n  // Get audio data\n  audioData = getAudioData();\n\n  // Detect beat and trigger flash\n  if (audioData.beat > 0) {\n    beatFlashIntensity = 1.0;\n    lastBeatTime = p.millis();\n  }\n\n  // Decay flash intensity\n  beatFlashIntensity *= 0.85;\n\n  // Background: black when no beat, white when beat detected\n  const bgColor = p.lerp(0, 255, beatFlashIntensity);\n  p.background(bgColor);\n\n  // Center circle that scales with beat\n  p.push();\n  p.translate(p.width / 2, p.height / 2);\n\n  // Circle size based on beat flash\n  const baseSize = 200;\n  const circleSize = baseSize + (beatFlashIntensity * 400);\n\n  // Circle color: white when beat, black otherwise\n  const circleColor = p.lerp(255, 0, beatFlashIntensity);\n  p.fill(circleColor);\n  p.noStroke();\n  p.circle(0, 0, circleSize);\n\n  p.pop();\n\n  // Debug info\n  p.fill(audioData.beat > 0 ? 0 : 255);\n  p.textAlign(p.LEFT, p.TOP);\n  p.textSize(16);\n  p.text(`Beat: ${audioData.beat.toFixed(3)}`, 10, 10);\n  p.text(`Energy: ${audioData.energy.toFixed(3)}`, 10, 30);\n  p.text(`Time: ${(p.millis() / 1000).toFixed(1)}s`, 10, 50);\n  p.text(`Playing: ${getIsPlaying()}`, 10, 70);\n}\n\n/**\n * Start button click handler\n */\nexport async function onPlayClick(p) {\n  await startAudio(config.transport.bpm);\n}\n\n/**\n * Stop button click handler\n */\nexport function onStopClick(p) {\n  stopAudio();\n  beatFlashIntensity = 0;\n}\n\n/**\n * Cleanup when atom is disposed\n */\nexport async function dispose() {\n  await cleanupAudio();\n}\n",
    "notes": "",
    "configJson": "{\n  \"type\": \"audio-visual\",\n  \"synth\": {\n    \"type\": \"membrane\",\n    \"pitchDecay\": 0.05,\n    \"octaves\": 3,\n    \"envelope\": {\n      \"attack\": 0.001,\n      \"decay\": 0.1,\n      \"sustain\": 0.0,\n      \"release\": 0.1\n    }\n  },\n  \"sequence\": {\n    \"notes\": [\"C2\", \"C2\", \"C2\", \"C2\", \"C2\", \"C2\", \"C2\", \"C2\", \"C2\", \"C2\"],\n    \"duration\": \"16n\",\n    \"interval\": \"2n\"\n  },\n  \"transport\": {\n    \"bpm\": 60\n  },\n  \"analysis\": {\n    \"fftSize\": 512,\n    \"smoothing\": 0.3,\n    \"outputSmoothing\": 0.1,\n    \"beatThreshold\": 0.3\n  }\n}\n"
  },
  {
    "slug": "2026-01-30-av1",
    "title": "av1",
    "date": "2026-01-30",
    "type": "audio-visual",
    "stage": "idea",
    "thumbnailUrl": "/thumbnails/2026-01-30-av1.webp",
    "code": "import p5 from 'p5';\nimport GUI from 'lil-gui';\nimport { initAudio, startAudio, stopAudio, getAudioData, cleanupAudio } from './audio.js';\nimport { applyMapping } from '../../lib/audio/smoothing.js';\n\nlet p5Instance;\n\nconst sketch = (p) => {\n  // --- Config ---\n  let config = {\n    // Visual parameters\n    bgHue: 240,\n    baseSize: 100,\n    particleCount: 60,\n    rotationSpeed: 0.5,\n\n    // Audio-visual mapping\n    bassSizeScale: 200,\n    midsHueShift: 120,\n    trebleDetail: 8,\n    beatFlash: 0.8,\n\n    // Audio config\n    synth: {\n      type: 'mono',\n      oscillator: { type: 'triangle' },\n      envelope: { attack: 0.01, decay: 0.3, sustain: 0.4, release: 0.8 }\n    },\n    sequence: {\n      notes: ['C4', 'E4', 'G4', 'B4', 'C5', null, 'G4', 'E4'],\n      duration: '8n',\n      interval: '8n'\n    },\n    effects: {\n      reverb: { decay: 3.0, wet: 0.4 }\n    },\n    transport: { bpm: 120 },\n    analysis: {\n      fftSize: 1024,\n      smoothing: 0.8,\n      outputSmoothing: 0.15,\n      beatThreshold: 0.15\n    }\n  };\n\n  let gui;\n  let time = 0;\n  let audioInitialized = false;\n\n  p.setup = () => {\n    p.createCanvas(800, 800);\n    p.colorMode(p.HSB, 360, 100, 100, 100);\n    p.noStroke();\n    loadConfig();\n  };\n\n  p.draw = () => {\n    const audio = getAudioData();\n\n    // Background: subtle darkening based on envelope\n    const bgBrightness = 8 + audio.envelope * 5;\n    p.background(config.bgHue, 20, bgBrightness);\n\n    // Beat flash overlay\n    if (audio.beat > 0.1) {\n      p.fill(0, 0, 100, audio.beat * config.beatFlash * 100);\n      p.rect(0, 0, p.width, p.height);\n    }\n\n    p.push();\n    p.translate(p.width / 2, p.height / 2);\n\n    // Rotation driven by treble\n    const rotation = time * config.rotationSpeed + audio.treble * Math.PI;\n    p.rotate(rotation);\n\n    // Number of elements driven by treble detail\n    const numElements = Math.floor(config.trebleDetail + audio.highMid * 12);\n\n    // Size driven by bass\n    const size = applyMapping(audio.bass, {\n      min: config.baseSize * 0.5,\n      max: config.baseSize + config.bassSizeScale,\n      curve: 'cubicOut'\n    });\n\n    // Draw audio-reactive ring of circles\n    for (let i = 0; i < numElements; i++) {\n      const angle = (p.TWO_PI / numElements) * i;\n      const radius = size + audio.mid * 50;\n\n      const x = p.cos(angle) * radius;\n      const y = p.sin(angle) * radius;\n\n      // Hue shifts with mids\n      const hue = (config.bgHue + config.midsHueShift * audio.mids + i * (360 / numElements)) % 360;\n      const elementSize = 10 + audio.bass * 30 + p.sin(time + i) * 5;\n      const alpha = 60 + audio.energy * 40;\n\n      p.fill(hue, 70 + audio.treble * 30, 80 + audio.envelope * 20, alpha);\n      p.circle(x, y, elementSize);\n    }\n\n    // Inner pulsing core\n    const coreSize = 30 + audio.envelope * 60 + audio.bass * 40;\n    const coreHue = (config.bgHue + 180 + audio.mids * config.midsHueShift) % 360;\n    p.fill(coreHue, 60, 90, 80);\n    p.circle(0, 0, coreSize);\n\n    p.pop();\n\n    time += 0.02;\n  };\n\n  async function loadConfig() {\n    try {\n      const response = await fetch('./config.json');\n      const saved = await response.json();\n      // Merge saved config (preserving nested objects)\n      config = deepMerge(config, saved);\n    } catch (e) {\n      console.log('No saved config, using defaults');\n    }\n\n    // Initialize audio with config\n    initAudio(config);\n    audioInitialized = true;\n\n    setupGUI();\n    setupTransportButtons();\n  }\n\n  function setupTransportButtons() {\n    const playBtn = document.getElementById('playBtn');\n    const stopBtn = document.getElementById('stopBtn');\n\n    if (playBtn) {\n      playBtn.addEventListener('click', async () => {\n        await startAudio(config.transport.bpm);\n        playBtn.classList.add('active');\n      });\n    }\n\n    if (stopBtn) {\n      stopBtn.addEventListener('click', () => {\n        stopAudio();\n        if (playBtn) playBtn.classList.remove('active');\n      });\n    }\n  }\n\n  function setupGUI() {\n    gui = new GUI({ title: 'av1' });\n\n    // Visual controls\n    const visFolder = gui.addFolder('Visual');\n    visFolder.add(config, 'bgHue', 0, 360).name('Background Hue');\n    visFolder.add(config, 'baseSize', 30, 300).name('Base Size');\n    visFolder.add(config, 'particleCount', 10, 100).step(1).name('Particles');\n    visFolder.add(config, 'rotationSpeed', 0, 3).name('Rotation');\n\n    // Audio-visual mapping controls\n    const mapFolder = gui.addFolder('Audio Mapping');\n    mapFolder.add(config, 'bassSizeScale', 0, 500).name('Bass -> Size');\n    mapFolder.add(config, 'midsHueShift', 0, 360).name('Mids -> Hue');\n    mapFolder.add(config, 'trebleDetail', 3, 24).step(1).name('Treble -> Detail');\n    mapFolder.add(config, 'beatFlash', 0, 1).name('Beat Flash');\n\n    // Transport\n    const transportFolder = gui.addFolder('Transport');\n    transportFolder.add(config.transport, 'bpm', 40, 200).step(1).name('BPM');\n\n    gui.onChange(() => {\n      console.log('Copy to config.json:', JSON.stringify(config, null, 2));\n    });\n  }\n\n  function deepMerge(target, source) {\n    const result = { ...target };\n    for (const key of Object.keys(source)) {\n      if (source[key] && typeof source[key] === 'object' && !Array.isArray(source[key])) {\n        result[key] = deepMerge(target[key] || {}, source[key]);\n      } else {\n        result[key] = source[key];\n      }\n    }\n    return result;\n  }\n};\n\np5Instance = new p5(sketch);\n\n// Vite HMR cleanup\nif (import.meta.hot) {\n  import.meta.hot.dispose(async () => {\n    await cleanupAudio();\n    if (p5Instance) {\n      p5Instance.remove();\n      p5Instance = null;\n    }\n  });\n}\n",
    "notes": "# av1\n\n**Created:** 2026-01-30\n**Stage:** idea\n**Type:** audio-visual\n\n## Intent\nWhat audio-visual relationship am I exploring? What should the viewer feel?\n\n## Audio Design\n- Synth type:\n- Key/scale:\n- Tempo:\n- Effects:\n\n## Visual Design\n- What shapes/patterns?\n- Color palette:\n- Movement style:\n\n## Audio-Visual Mapping\n- Bass drives:\n- Mids drive:\n- Treble drives:\n- Beat triggers:\n\n## Technical Decisions\n- Why these mappings?\n- Smoothing/easing choices:\n\n## Published\n- **YouTube:** https://www.youtube.com/watch?v=JD9yX-VWWxI (2026-01-30 12:59:26)\n\n## Session Log\n\n### 2026-01-30 14:05\n- Created audio-visual atom\n- Initial setup\n\n### 2026-01-30 11:05:29\n- \n",
    "configJson": "{\n  \"type\": \"audio-visual\",\n  \"bgHue\": 240,\n  \"baseSize\": 100,\n  \"particleCount\": 60,\n  \"rotationSpeed\": 0.5,\n  \"bassSizeScale\": 200,\n  \"midsHueShift\": 120,\n  \"trebleDetail\": 8,\n  \"beatFlash\": 0.8,\n  \"synth\": {\n    \"type\": \"mono\",\n    \"oscillator\": { \"type\": \"triangle\" },\n    \"envelope\": {\n      \"attack\": 0.01,\n      \"decay\": 0.3,\n      \"sustain\": 0.4,\n      \"release\": 0.8\n    }\n  },\n  \"sequence\": {\n    \"notes\": [\"C4\", \"E4\", \"G4\", \"B4\", \"C5\", null, \"G4\", \"E4\"],\n    \"duration\": \"8n\",\n    \"interval\": \"8n\"\n  },\n  \"effects\": {\n    \"reverb\": {\n      \"decay\": 3.0,\n      \"wet\": 0.4\n    }\n  },\n  \"transport\": {\n    \"bpm\": 120\n  },\n  \"analysis\": {\n    \"fftSize\": 1024,\n    \"smoothing\": 0.8,\n    \"outputSmoothing\": 0.15,\n    \"beatThreshold\": 0.15\n  }\n}\n"
  },
  {
    "slug": "2026-01-30-my-first-sketch",
    "title": "my-first-sketch",
    "date": "2026-01-30",
    "type": "visual",
    "stage": "idea",
    "thumbnailUrl": "/thumbnails/2026-01-30-my-first-sketch.webp",
    "code": "import p5 from 'p5';\nimport GUI from 'lil-gui';\n\nlet p5Instance;\n\nconst sketch = (p) => {\n  let config = {\n    bgHue: 200,\n    shapeHue: 30,\n    size: 100,\n    speed: 1,\n    noiseScale: 0.01\n  };\n\n  let time = 0;\n  let gui;\n\n  p.setup = () => {\n    p.createCanvas(800, 800);\n    p.colorMode(p.HSB, 360, 100, 100);\n    p.noStroke();\n    loadConfig();\n  };\n\n  p.draw = () => {\n    p.background(config.bgHue, 30, 95);\n    const x = p.width / 2 + p.noise(time) * 50 - 25;\n    const y = p.height / 2 + p.noise(time + 100) * 50 - 25;\n    const size = config.size + p.sin(time * config.speed) * 20;\n    p.fill(config.shapeHue, 80, 90);\n    p.circle(x, y, size);\n    time += config.noiseScale;\n  };\n\n  async function loadConfig() {\n    try {\n      const response = await fetch('./config.json');\n      const saved = await response.json();\n      Object.assign(config, saved.controllers || saved);\n    } catch (e) {\n      console.log('No saved config, using defaults');\n    }\n    setupGUI();\n  }\n\n  function setupGUI() {\n    gui = new GUI({ title: 'my-first-sketch Parameters' });\n    gui.add(config, 'bgHue', 0, 360).name('Background Hue');\n    gui.add(config, 'shapeHue', 0, 360).name('Shape Hue');\n    gui.add(config, 'size', 50, 200).name('Size');\n    gui.add(config, 'speed', 0.1, 5).name('Speed');\n    gui.add(config, 'noiseScale', 0.001, 0.1).name('Noise Scale');\n\n    gui.onChange(() => {\n      console.log('Copy to config.json:', JSON.stringify({ controllers: config }, null, 2));\n    });\n  }\n};\n\np5Instance = new p5(sketch);\n\n// Vite HMR cleanup (prevents canvas duplication)\nif (import.meta.hot) {\n  import.meta.hot.dispose(() => {\n    if (p5Instance) {\n      p5Instance.remove();\n      p5Instance = null;\n    }\n  });\n}\n",
    "notes": "# my-first-sketch\n\n**Created:** 2026-01-30\n**Stage:** idea\n\n## Intent\nWhat am I exploring with this atom? What feeling or concept?\n\n## Technical Decisions\n- Why this approach?\n- What techniques/algorithms?\n\n## Session Log\n\n### 2026-01-30 10:20\n- Created atom\n- Initial setup\n\n### 2026-01-30 09:21:31\n- \n\n### 2026-01-30 09:21:35\n- \n\n### 2026-01-30 09:26:01\n- \n\n### 2026-01-30 09:51:19\nlala\n- \n",
    "configJson": "{\n  \"controllers\": {\n    \"bgHue\": 200,\n    \"shapeHue\": 30,\n    \"size\": 100,\n    \"speed\": 1,\n    \"noiseScale\": 0.01\n  }\n}\n"
  },
  {
    "slug": "2026-01-30-test-verify",
    "title": "test-verify",
    "date": "2026-01-30",
    "type": "visual",
    "stage": "idea",
    "thumbnailUrl": "/thumbnails/2026-01-30-test-verify.webp",
    "code": "import p5 from 'p5';\nimport GUI from 'lil-gui';\n\nlet p5Instance;\n\nconst sketch = (p) => {\n  let config = {\n    bgHue: 200,\n    shapeHue: 30,\n    size: 100,\n    speed: 1,\n    noiseScale: 0.01\n  };\n\n  let time = 0;\n  let gui;\n\n  p.setup = () => {\n    p.createCanvas(800, 800);\n    p.colorMode(p.HSB, 360, 100, 100);\n    p.noStroke();\n    loadConfig();\n  };\n\n  p.draw = () => {\n    p.background(config.bgHue, 30, 95);\n    const x = p.width / 2 + p.noise(time) * 50 - 25;\n    const y = p.height / 2 + p.noise(time + 100) * 50 - 25;\n    const size = config.size + p.sin(time * config.speed) * 20;\n    p.fill(config.shapeHue, 80, 90);\n    p.circle(x, y, size);\n    time += config.noiseScale;\n  };\n\n  async function loadConfig() {\n    try {\n      const response = await fetch('./config.json');\n      const saved = await response.json();\n      Object.assign(config, saved.controllers || saved);\n    } catch (e) {\n      console.log('No saved config, using defaults');\n    }\n    setupGUI();\n  }\n\n  function setupGUI() {\n    gui = new GUI({ title: 'test-verify Parameters' });\n    gui.add(config, 'bgHue', 0, 360).name('Background Hue');\n    gui.add(config, 'shapeHue', 0, 360).name('Shape Hue');\n    gui.add(config, 'size', 50, 200).name('Size');\n    gui.add(config, 'speed', 0.1, 5).name('Speed');\n    gui.add(config, 'noiseScale', 0.001, 0.1).name('Noise Scale');\n\n    gui.onChange(() => {\n      console.log('Copy to config.json:', JSON.stringify({ controllers: config }, null, 2));\n    });\n  }\n};\n\np5Instance = new p5(sketch);\n\n// Vite HMR cleanup (prevents canvas duplication)\nif (import.meta.hot) {\n  import.meta.hot.dispose(() => {\n    if (p5Instance) {\n      p5Instance.remove();\n      p5Instance = null;\n    }\n  });\n}\n",
    "notes": "# test-verify\n\n**Created:** 2026-01-30\n**Stage:** idea\n\n## Intent\nWhat am I exploring with this atom? What feeling or concept?\n\n## Technical Decisions\n- Why this approach?\n- What techniques/algorithms?\n\n## Session Log\n\n### 2026-01-30 07:07\n- Created atom\n- Initial setup\n\n### 2026-01-30 09:25:46\n- \n",
    "configJson": "{\n  \"controllers\": {\n    \"bgHue\": 200,\n    \"shapeHue\": 30,\n    \"size\": 100,\n    \"speed\": 1,\n    \"noiseScale\": 0.01\n  }\n}\n"
  },
  {
    "slug": "2026-01-29-workflow-test",
    "title": "workflow-test",
    "date": "2026-01-29",
    "type": "visual",
    "stage": "idea",
    "thumbnailUrl": "/thumbnails/2026-01-29-workflow-test.webp",
    "code": "import p5 from 'p5';\nimport GUI from 'lil-gui';\n\nlet p5Instance;\n\nconst sketch = (p) => {\n  let config = {\n    bgHue: 200,\n    shapeHue: 30,\n    size: 100,\n    speed: 1,\n    noiseScale: 0.01\n  };\n\n  let time = 0;\n  let gui;\n\n  p.setup = () => {\n    p.createCanvas(800, 800);\n    p.colorMode(p.HSB, 360, 100, 100);\n    p.noStroke();\n    loadConfig();\n  };\n\n  p.draw = () => {\n    p.background(config.bgHue, 30, 95);\n    const x = p.width / 2 + p.noise(time) * 50 - 25;\n    const y = p.height / 2 + p.noise(time + 100) * 50 - 25;\n    const size = config.size + p.sin(time * config.speed) * 20;\n    p.fill(config.shapeHue, 80, 90);\n    p.circle(x, y, size);\n    time += config.noiseScale;\n  };\n\n  async function loadConfig() {\n    try {\n      const response = await fetch('./config.json');\n      const saved = await response.json();\n      Object.assign(config, saved.controllers || saved);\n    } catch (e) {\n      console.log('No saved config, using defaults');\n    }\n    setupGUI();\n  }\n\n  function setupGUI() {\n    gui = new GUI({ title: 'workflow-test Parameters' });\n    gui.add(config, 'bgHue', 0, 360).name('Background Hue');\n    gui.add(config, 'shapeHue', 0, 360).name('Shape Hue');\n    gui.add(config, 'size', 50, 200).name('Size');\n    gui.add(config, 'speed', 0.1, 5).name('Speed');\n    gui.add(config, 'noiseScale', 0.001, 0.1).name('Noise Scale');\n\n    gui.onChange(() => {\n      console.log('Copy to config.json:', JSON.stringify({ controllers: config }, null, 2));\n    });\n  }\n};\n\np5Instance = new p5(sketch);\n\n// Vite HMR cleanup (prevents canvas duplication)\nif (import.meta.hot) {\n  import.meta.hot.dispose(() => {\n    if (p5Instance) {\n      p5Instance.remove();\n      p5Instance = null;\n    }\n  });\n}\n",
    "notes": "# workflow-test\n\n**Created:** 2026-01-29\n**Stage:** idea\n\n## Intent\nWhat am I exploring with this atom? What feeling or concept?\n\n## Technical Decisions\n- Why this approach?\n- What techniques/algorithms?\n\n## Session Log\n\n### 2026-01-29 21:50\n- Created atom\n- Initial setup\n\n### 2026-01-30 09:28:13\n- \n",
    "configJson": "{\n  \"controllers\": {\n    \"bgHue\": 200,\n    \"shapeHue\": 30,\n    \"size\": 100,\n    \"speed\": 1,\n    \"noiseScale\": 0.01\n  }\n}\n"
  }
]
