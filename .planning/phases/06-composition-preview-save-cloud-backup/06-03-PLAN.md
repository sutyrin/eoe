---
phase: 06-composition-preview-save-cloud-backup
plan: 03
type: execute
wave: 2
depends_on: ["06-02"]
duration: 4h
autonomous: true
files_modified:
  - portfolio/src/scripts/backup-client.ts
  - portfolio/src/scripts/db.ts
  - portfolio/src/scripts/composition-store.ts
  - portfolio/src/components/OfflineIndicator.astro
  - portfolio/astro.config.mjs
  - server/backup-server.js
  - server/package.json
  - server/Dockerfile
  - docker-compose.yml

must_haves:
  truths:
    - "Cloud backup server accepts POST /api/backup with JSON payload containing atoms, notes, compositions, snapshots"
    - "Server stores backups as timestamped JSON files in a data directory"
    - "Client auto-backs up all creative content on app close (beforeunload/visibilitychange)"
    - "Auto-retry on failure: 3 attempts with exponential backoff"
    - "GET /api/backup/latest returns the most recent backup"
    - "GET /api/backup/list returns all available backups with timestamps"
    - "POST /api/restore accepts a backup ID and returns the full backup data"
    - "Selective restore supported: user can pick which items to restore"
    - "Backup includes atoms, voice notes (metadata only, not audio blobs), compositions, snapshots"
    - "No storage limits enforced (user manages their own storage)"
    - "All backups kept indefinitely (full archive)"
  artifacts:
    - path: "portfolio/src/scripts/backup-client.ts"
      provides: "Client-side backup/restore API: createBackup, listBackups, restoreBackup"
      contains: "createBackup"
    - path: "server/backup-server.js"
      provides: "Express server with backup/restore endpoints"
      contains: "/api/backup"
    - path: "server/Dockerfile"
      provides: "Docker container for backup server (Node.js)"
      contains: "node"
  key_links:
    - from: "portfolio/src/scripts/backup-client.ts"
      to: "portfolio/src/scripts/db.ts"
      via: "import { getDB, getAllAtomsSorted }"
      pattern: "getAllAtomsSorted"
    - from: "portfolio/src/scripts/backup-client.ts"
      to: "portfolio/src/scripts/composition-store.ts"
      via: "import { getAllCompositions }"
      pattern: "getAllCompositions"
    - from: "portfolio/src/scripts/backup-client.ts"
      to: "server/backup-server.js"
      via: "HTTP POST /api/backup"
      pattern: "/api/backup"
---

<objective>
Build the cloud backup service: a simple Node.js HTTP server that accepts backup uploads and serves restores, plus a client-side backup module that collects all creative content from IndexedDB and sends it to the server. After this plan, the app auto-backs up atoms, notes, compositions, and snapshots when the user closes the app (or on demand), and can restore selectively from any previous backup.

Purpose: Cloud backup is the safety net that enables multi-device continuity. If a user loses their phone or clears browser data, they can restore their entire creative library from the server. The indefinite retention means they can roll back to any previous state.

Output: backup-server.js (Express), backup-client.ts (browser), auto-backup on app close, list/restore endpoints, Docker deployment.
</objective>

<execution_context>
@/home/pavel/.claude/get-shit-done/workflows/execute-plan.md
@/home/pavel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-composition-preview-save-cloud-backup/06-CONTEXT.md
@portfolio/src/scripts/db.ts
@portfolio/src/scripts/composition-store.ts
@portfolio/src/scripts/composition-snapshot.ts
@portfolio/Dockerfile
@portfolio/docker-compose.yml
@portfolio/nginx.conf
@deploy.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create backup server with Express</name>
  <files>
    server/backup-server.js
    server/package.json
  </files>
  <action>
Create a standalone Node.js backup server using Express. This runs as a separate container alongside the existing nginx-served portfolio.

**Create server/ directory and server/package.json:**

```json
{
  "name": "eoe-backup-server",
  "version": "1.0.0",
  "private": true,
  "type": "module",
  "scripts": {
    "start": "node backup-server.js"
  },
  "dependencies": {
    "cors": "^2.8.5",
    "express": "^4.21.0"
  }
}
```

**Create server/backup-server.js:**

```javascript
/**
 * EOE Backup Server
 *
 * Simple HTTP server for cloud backup/restore of creative content.
 *
 * Endpoints:
 * - POST /api/backup          Upload a full backup (atoms, notes, compositions, snapshots)
 * - GET  /api/backup/latest   Get the most recent backup
 * - GET  /api/backup/list     List all available backups with timestamps and sizes
 * - POST /api/restore         Restore a specific backup by ID (returns full data)
 * - GET  /api/backup/:id      Get a specific backup by ID
 * - DELETE /api/backup/:id    Delete a specific backup
 * - GET  /api/health          Health check
 *
 * Storage: JSON files in /data/backups/ directory
 * Retention: All backups kept indefinitely
 * Limits: None enforced (user manages storage)
 */

import express from 'express';
import cors from 'cors';
import { readdir, readFile, writeFile, mkdir, unlink, stat } from 'fs/promises';
import { join } from 'path';
import { existsSync } from 'fs';

const app = express();
const PORT = process.env.PORT || 3081;
const DATA_DIR = process.env.DATA_DIR || '/data/backups';

// Middleware
app.use(cors());
app.use(express.json({ limit: '50mb' })); // Large backups with atom code

// Ensure data directory exists
async function ensureDataDir() {
  if (!existsSync(DATA_DIR)) {
    await mkdir(DATA_DIR, { recursive: true });
    console.log(`[backup] Created data directory: ${DATA_DIR}`);
  }
}

// Generate backup filename
function backupFilename(id) {
  return `backup-${id}.json`;
}

// Generate backup ID (timestamp-based for sorting)
function generateBackupId() {
  const now = new Date();
  const ts = now.toISOString().replace(/[:.]/g, '-');
  const rand = Math.random().toString(36).substring(2, 6);
  return `${ts}-${rand}`;
}

// ---- Endpoints ----

/**
 * POST /api/backup
 * Upload a full backup.
 *
 * Body: {
 *   atoms: AtomMetadata[],
 *   compositions: Composition[],
 *   snapshots: CompositionSnapshot[],
 *   voiceNotes: VoiceNoteMetadata[],  (metadata only, no blobs)
 *   configOverrides: ConfigOverride[],
 *   clientTimestamp: string  (ISO timestamp from client)
 * }
 *
 * Returns: { id, timestamp, size }
 */
app.post('/api/backup', async (req, res) => {
  try {
    const backupData = req.body;
    if (!backupData || typeof backupData !== 'object') {
      return res.status(400).json({ error: 'Invalid backup data' });
    }

    const id = generateBackupId();
    const timestamp = new Date().toISOString();

    const backup = {
      id,
      timestamp,
      clientTimestamp: backupData.clientTimestamp || timestamp,
      version: 1,  // Backup format version
      data: {
        atoms: backupData.atoms || [],
        compositions: backupData.compositions || [],
        snapshots: backupData.snapshots || [],
        voiceNotes: backupData.voiceNotes || [],
        configOverrides: backupData.configOverrides || [],
      },
    };

    const json = JSON.stringify(backup, null, 2);
    const filepath = join(DATA_DIR, backupFilename(id));
    await writeFile(filepath, json, 'utf-8');

    const size = Buffer.byteLength(json, 'utf-8');
    console.log(`[backup] Created: ${id} (${Math.round(size / 1024)}KB)`);

    res.json({ id, timestamp, size });
  } catch (err) {
    console.error('[backup] Error creating backup:', err);
    res.status(500).json({ error: 'Failed to create backup' });
  }
});

/**
 * GET /api/backup/latest
 * Get the most recent backup.
 */
app.get('/api/backup/latest', async (req, res) => {
  try {
    const files = await readdir(DATA_DIR);
    const backupFiles = files
      .filter(f => f.startsWith('backup-') && f.endsWith('.json'))
      .sort()
      .reverse();

    if (backupFiles.length === 0) {
      return res.status(404).json({ error: 'No backups found' });
    }

    const filepath = join(DATA_DIR, backupFiles[0]);
    const content = await readFile(filepath, 'utf-8');
    const backup = JSON.parse(content);

    res.json(backup);
  } catch (err) {
    console.error('[backup] Error fetching latest:', err);
    res.status(500).json({ error: 'Failed to fetch latest backup' });
  }
});

/**
 * GET /api/backup/list
 * List all available backups with metadata.
 */
app.get('/api/backup/list', async (req, res) => {
  try {
    const files = await readdir(DATA_DIR);
    const backupFiles = files
      .filter(f => f.startsWith('backup-') && f.endsWith('.json'))
      .sort()
      .reverse();

    const backups = [];
    for (const file of backupFiles) {
      const filepath = join(DATA_DIR, file);
      const stats = await stat(filepath);

      // Read just enough to get metadata (not full data)
      const content = await readFile(filepath, 'utf-8');
      const backup = JSON.parse(content);

      backups.push({
        id: backup.id,
        timestamp: backup.timestamp,
        clientTimestamp: backup.clientTimestamp,
        size: stats.size,
        counts: {
          atoms: backup.data?.atoms?.length || 0,
          compositions: backup.data?.compositions?.length || 0,
          snapshots: backup.data?.snapshots?.length || 0,
          voiceNotes: backup.data?.voiceNotes?.length || 0,
        },
      });
    }

    res.json({ backups });
  } catch (err) {
    console.error('[backup] Error listing backups:', err);
    res.status(500).json({ error: 'Failed to list backups' });
  }
});

/**
 * GET /api/backup/:id
 * Get a specific backup by ID.
 */
app.get('/api/backup/:id', async (req, res) => {
  try {
    const filepath = join(DATA_DIR, backupFilename(req.params.id));
    if (!existsSync(filepath)) {
      return res.status(404).json({ error: 'Backup not found' });
    }

    const content = await readFile(filepath, 'utf-8');
    const backup = JSON.parse(content);
    res.json(backup);
  } catch (err) {
    console.error('[backup] Error fetching backup:', err);
    res.status(500).json({ error: 'Failed to fetch backup' });
  }
});

/**
 * POST /api/restore
 * Restore from a specific backup.
 * Body: { backupId: string, items?: { atoms?: boolean, compositions?: boolean, snapshots?: boolean } }
 *
 * If items is omitted, returns full backup data.
 * If items is specified, returns only selected categories (selective restore).
 */
app.post('/api/restore', async (req, res) => {
  try {
    const { backupId, items } = req.body;
    if (!backupId) {
      return res.status(400).json({ error: 'backupId required' });
    }

    const filepath = join(DATA_DIR, backupFilename(backupId));
    if (!existsSync(filepath)) {
      return res.status(404).json({ error: 'Backup not found' });
    }

    const content = await readFile(filepath, 'utf-8');
    const backup = JSON.parse(content);

    // Selective restore: filter data based on items parameter
    if (items && typeof items === 'object') {
      const filtered = {};
      if (items.atoms) filtered.atoms = backup.data.atoms;
      if (items.compositions) filtered.compositions = backup.data.compositions;
      if (items.snapshots) filtered.snapshots = backup.data.snapshots;
      if (items.voiceNotes) filtered.voiceNotes = backup.data.voiceNotes;
      if (items.configOverrides) filtered.configOverrides = backup.data.configOverrides;

      return res.json({
        id: backup.id,
        timestamp: backup.timestamp,
        data: filtered,
      });
    }

    // Full restore
    res.json(backup);
  } catch (err) {
    console.error('[backup] Error restoring:', err);
    res.status(500).json({ error: 'Failed to restore backup' });
  }
});

/**
 * DELETE /api/backup/:id
 * Delete a specific backup.
 */
app.delete('/api/backup/:id', async (req, res) => {
  try {
    const filepath = join(DATA_DIR, backupFilename(req.params.id));
    if (!existsSync(filepath)) {
      return res.status(404).json({ error: 'Backup not found' });
    }

    await unlink(filepath);
    console.log(`[backup] Deleted: ${req.params.id}`);
    res.json({ deleted: true });
  } catch (err) {
    console.error('[backup] Error deleting backup:', err);
    res.status(500).json({ error: 'Failed to delete backup' });
  }
});

/**
 * GET /api/health
 * Health check endpoint.
 */
app.get('/api/health', (req, res) => {
  res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// ---- Start ----

await ensureDataDir();

app.listen(PORT, () => {
  console.log(`[backup] EOE Backup Server running on port ${PORT}`);
  console.log(`[backup] Data directory: ${DATA_DIR}`);
});
```

Key design decisions:
- Standalone Express server (separate from nginx portfolio)
- JSON file storage (simple, human-readable, easy to debug)
- Timestamp-based IDs for natural sort ordering
- Selective restore via items filter
- 50MB body limit (large backups with inline atom code)
- No authentication in v1.1 (single-user, private server)
- All backups kept indefinitely
  </action>
  <verify>
1. server/backup-server.js exists with Express endpoints
2. server/package.json has express and cors dependencies
3. POST /api/backup accepts and stores backup data
4. GET /api/backup/latest returns most recent backup
5. GET /api/backup/list returns all backups with metadata
6. POST /api/restore supports selective restore via items filter
7. Health check endpoint at /api/health
8. No storage limits enforced
  </verify>
  <done>
Backup server created with Express: POST backup, GET latest, GET list, POST restore (with selective filtering), DELETE backup, health check. JSON file storage in /data/backups/. No limits, indefinite retention.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Docker infrastructure for backup server</name>
  <files>
    server/Dockerfile
    docker-compose.yml
  </files>
  <action>
Create Docker configuration for the backup server and update the root docker-compose.yml to run both the portfolio and backup server.

**Create server/Dockerfile:**

```dockerfile
FROM node:20-alpine
WORKDIR /app

# Copy package files
COPY server/package.json server/package-lock.json* ./

# Install dependencies
RUN npm install --production

# Copy server code
COPY server/backup-server.js ./

# Create data directory
RUN mkdir -p /data/backups

# Expose port
EXPOSE 3081

# Health check
HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
  CMD wget --quiet --tries=1 --spider http://localhost:3081/api/health || exit 1

CMD ["node", "backup-server.js"]
```

**Create a new root-level docker-compose.yml** (or update the existing one if it's at root level -- check first). The existing docker-compose.yml is in portfolio/. Create a new one at the root that orchestrates both services.

Actually, looking at the existing setup: portfolio/docker-compose.yml handles just the portfolio. The deploy.sh rsyncs from root and runs `cd portfolio && docker compose up`. We need to add the backup server alongside.

**Update portfolio/docker-compose.yml** to add the backup server:

```yaml
services:
  eoe-portfolio:
    build:
      context: ..
      dockerfile: portfolio/Dockerfile
    container_name: eoe-portfolio
    restart: unless-stopped
    ports:
      - "3080:80"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/"]
      interval: 30s
      timeout: 5s
      retries: 3

  eoe-backup:
    build:
      context: ..
      dockerfile: server/Dockerfile
    container_name: eoe-backup
    restart: unless-stopped
    ports:
      - "3081:3081"
    environment:
      - PORT=3081
      - DATA_DIR=/data/backups
    volumes:
      - backup-data:/data/backups
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3081/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3

volumes:
  backup-data:
    driver: local
```

**Update portfolio/nginx.conf** to proxy /api/ requests to the backup server:

```nginx
server {
    listen 80;
    server_name _;
    root /usr/share/nginx/html;
    index index.html;

    # SPA/PWA fallback
    location / {
        try_files $uri $uri/ /index.html;
    }

    # Proxy API requests to backup server
    location /api/ {
        proxy_pass http://eoe-backup:3081;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_read_timeout 60s;
        client_max_body_size 50m;
    }

    # Cache static assets aggressively
    location /_astro/ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # Service worker must not be cached
    location = /sw.js {
        expires off;
        add_header Cache-Control "no-cache, no-store, must-revalidate";
    }

    location = /registerSW.js {
        expires off;
        add_header Cache-Control "no-cache, no-store, must-revalidate";
    }
}
```

The key addition is the `/api/` location block that proxies to the backup server container. Docker Compose networking allows services to reference each other by service name (`eoe-backup`).

**Update portfolio/astro.config.mjs** to add the /api/ runtime caching rule. In the workbox runtimeCaching array, the existing NetworkOnly rule for `/api/` should remain as-is since backup calls should not be cached by the service worker:

```javascript
{
  // API calls (backup, restore) - never cache
  urlPattern: /\/api\/.*/,
  handler: 'NetworkOnly'
}
```

This already exists in the config, so no change needed here. Just verify it's present.
  </action>
  <verify>
1. server/Dockerfile exists and builds from node:20-alpine
2. portfolio/docker-compose.yml has both eoe-portfolio and eoe-backup services
3. eoe-backup mounts a persistent volume for /data/backups
4. nginx.conf has proxy_pass for /api/ to eoe-backup:3081
5. client_max_body_size is 50m (allows large backups)
6. /api/ is already set to NetworkOnly in workbox config
7. `cd portfolio && docker compose config` validates the compose file
  </verify>
  <done>
Docker infrastructure created: backup server Dockerfile, docker-compose.yml updated with both services and persistent volume, nginx reverse proxy for /api/ to backup server. Backup data persists across container restarts via Docker volume.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create backup client module</name>
  <files>
    portfolio/src/scripts/backup-client.ts
  </files>
  <action>
Create the client-side backup module that collects data from IndexedDB and sends it to the backup server.

**Create portfolio/src/scripts/backup-client.ts:**

```typescript
/**
 * Backup Client: Collects creative content from IndexedDB and
 * sends it to the cloud backup server.
 *
 * Features:
 * - createBackup(): Gather all data and upload to server
 * - listBackups(): Get available backups from server
 * - restoreFromBackup(): Download backup and write to IndexedDB
 * - Auto-retry: 3 attempts with exponential backoff
 * - Auto-backup: triggered on app close (visibilitychange)
 *
 * Backup scope: atoms, compositions, snapshots, voice notes (metadata),
 * config overrides. Voice note audio blobs are NOT backed up (too large).
 */

import { getDB, getAllAtomsSorted } from './db';
import type { AtomMetadata, VoiceNote, ConfigOverride } from './db';
import { getAllCompositions } from './composition-store';

const API_BASE = '/api';
const MAX_RETRIES = 3;
const RETRY_BASE_MS = 1000; // 1s, 2s, 4s exponential backoff

// ---- Types ----

export interface BackupSummary {
  id: string;
  timestamp: string;
  clientTimestamp: string;
  size: number;
  counts: {
    atoms: number;
    compositions: number;
    snapshots: number;
    voiceNotes: number;
  };
}

export interface BackupData {
  atoms: AtomMetadata[];
  compositions: unknown[];
  snapshots: unknown[];
  voiceNotes: VoiceNoteMetadata[];
  configOverrides: ConfigOverride[];
}

interface VoiceNoteMetadata {
  id: number;
  atomSlug: string;
  mimeType: string;
  transcript: string;
  createdAt: string;
  // audioBlob is NOT included (too large for cloud backup)
}

export type BackupStatus = 'idle' | 'backing-up' | 'success' | 'error';

// ---- State ----

let currentStatus: BackupStatus = 'idle';
let lastBackupTime: string | null = null;
let lastError: string | null = null;

// ---- Core Functions ----

/**
 * Create a full backup of all creative content.
 * Collects from IndexedDB and uploads to server.
 *
 * @returns Backup summary on success, null on failure
 */
export async function createBackup(): Promise<BackupSummary | null> {
  if (currentStatus === 'backing-up') {
    console.log('[backup] Backup already in progress');
    return null;
  }

  currentStatus = 'backing-up';
  dispatchStatusEvent();

  try {
    // Collect all data from IndexedDB
    const data = await collectBackupData();

    // Upload to server with retry
    const result = await fetchWithRetry(`${API_BASE}/backup`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        ...data,
        clientTimestamp: new Date().toISOString(),
      }),
    });

    if (!result.ok) {
      throw new Error(`Server returned ${result.status}`);
    }

    const summary = await result.json();

    // Mark items as synced in IndexedDB
    await markAsSynced();

    currentStatus = 'success';
    lastBackupTime = new Date().toISOString();
    lastError = null;
    dispatchStatusEvent();

    console.log(`[backup] Complete: ${summary.id} (${Math.round(summary.size / 1024)}KB)`);
    return summary;
  } catch (err) {
    currentStatus = 'error';
    lastError = err instanceof Error ? err.message : 'Unknown error';
    dispatchStatusEvent();

    console.error('[backup] Failed:', err);
    return null;
  }
}

/**
 * List all available backups from the server.
 */
export async function listBackups(): Promise<BackupSummary[]> {
  try {
    const res = await fetch(`${API_BASE}/backup/list`);
    if (!res.ok) throw new Error(`Server returned ${res.status}`);

    const data = await res.json();
    return data.backups || [];
  } catch (err) {
    console.error('[backup] Failed to list backups:', err);
    return [];
  }
}

/**
 * Restore from a specific backup.
 * Downloads backup data and writes selected items to IndexedDB.
 *
 * @param backupId - ID of the backup to restore from
 * @param items - Which categories to restore (all if omitted)
 * @returns Object describing what was restored, or null on failure
 */
export async function restoreFromBackup(
  backupId: string,
  items?: {
    atoms?: boolean;
    compositions?: boolean;
    snapshots?: boolean;
    voiceNotes?: boolean;
    configOverrides?: boolean;
  },
): Promise<{
  atomsRestored: number;
  compositionsRestored: number;
  snapshotsRestored: number;
} | null> {
  try {
    const res = await fetch(`${API_BASE}/restore`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ backupId, items }),
    });

    if (!res.ok) throw new Error(`Server returned ${res.status}`);

    const backup = await res.json();
    const data = backup.data;
    const db = await getDB();

    let atomsRestored = 0;
    let compositionsRestored = 0;
    let snapshotsRestored = 0;

    // Restore atoms
    if (data.atoms && data.atoms.length > 0) {
      const tx = db.transaction('atoms', 'readwrite');
      for (const atom of data.atoms) {
        await tx.store.put(atom);
        atomsRestored++;
      }
      await tx.done;
    }

    // Restore compositions
    if (data.compositions && data.compositions.length > 0) {
      const tx = db.transaction('compositions', 'readwrite');
      for (const comp of data.compositions) {
        await tx.store.put(comp);
        compositionsRestored++;
      }
      await tx.done;
    }

    // Restore snapshots
    if (data.snapshots && data.snapshots.length > 0) {
      const tx = db.transaction('snapshots', 'readwrite');
      for (const snap of data.snapshots) {
        await tx.store.put(snap);
        snapshotsRestored++;
      }
      await tx.done;
    }

    // Restore config overrides
    if (data.configOverrides && data.configOverrides.length > 0) {
      const tx = db.transaction('configOverrides', 'readwrite');
      for (const override of data.configOverrides) {
        await tx.store.put(override);
      }
      await tx.done;
    }

    console.log(`[backup] Restored: ${atomsRestored} atoms, ${compositionsRestored} compositions, ${snapshotsRestored} snapshots`);

    return { atomsRestored, compositionsRestored, snapshotsRestored };
  } catch (err) {
    console.error('[backup] Restore failed:', err);
    return null;
  }
}

/**
 * Get current backup status for UI display.
 */
export function getBackupStatus(): {
  status: BackupStatus;
  lastBackupTime: string | null;
  lastError: string | null;
} {
  return {
    status: currentStatus,
    lastBackupTime,
    lastError,
  };
}

// ---- Auto-backup on app close ----

let autoBackupEnabled = true;

/**
 * Enable auto-backup on app close.
 * Uses visibilitychange (more reliable than beforeunload on mobile).
 */
export function enableAutoBackup(): void {
  autoBackupEnabled = true;

  document.addEventListener('visibilitychange', handleVisibilityChange);
  window.addEventListener('beforeunload', handleBeforeUnload);
}

/**
 * Disable auto-backup.
 */
export function disableAutoBackup(): void {
  autoBackupEnabled = false;

  document.removeEventListener('visibilitychange', handleVisibilityChange);
  window.removeEventListener('beforeunload', handleBeforeUnload);
}

function handleVisibilityChange(): void {
  if (document.visibilityState === 'hidden' && autoBackupEnabled) {
    // Use sendBeacon for reliability (survives page close)
    triggerBackupBeacon();
  }
}

function handleBeforeUnload(): void {
  if (autoBackupEnabled) {
    triggerBackupBeacon();
  }
}

/**
 * Trigger backup using sendBeacon (reliable on page close).
 * sendBeacon is fire-and-forget: it survives page navigation/close.
 */
async function triggerBackupBeacon(): Promise<void> {
  try {
    const data = await collectBackupData();
    const payload = JSON.stringify({
      ...data,
      clientTimestamp: new Date().toISOString(),
    });

    // Try sendBeacon first (more reliable on close)
    if (navigator.sendBeacon) {
      const blob = new Blob([payload], { type: 'application/json' });
      const sent = navigator.sendBeacon(`${API_BASE}/backup`, blob);
      if (sent) {
        console.log('[backup] Beacon sent');
        return;
      }
    }

    // Fallback: regular fetch with keepalive
    fetch(`${API_BASE}/backup`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: payload,
      keepalive: true,
    }).catch(() => {
      // Best-effort on page close
    });
  } catch {
    // Best-effort on page close
  }
}

// ---- Helpers ----

/**
 * Collect all backup-worthy data from IndexedDB.
 */
async function collectBackupData(): Promise<BackupData> {
  const db = await getDB();

  // Atoms
  const atoms = await getAllAtomsSorted();

  // Compositions
  const compositions = await getAllCompositions();

  // Snapshots
  let snapshots: unknown[] = [];
  try {
    snapshots = await db.getAll('snapshots');
  } catch {
    // Snapshots store may not exist yet
  }

  // Voice notes (metadata only, no audio blobs)
  let voiceNotes: VoiceNoteMetadata[] = [];
  try {
    const allVoiceNotes = await db.getAll('voiceNotes') as VoiceNote[];
    voiceNotes = allVoiceNotes.map(vn => ({
      id: vn.id!,
      atomSlug: vn.atomSlug,
      mimeType: vn.mimeType,
      transcript: vn.transcript,
      createdAt: vn.createdAt,
    }));
  } catch {
    // Voice notes store may not be populated
  }

  // Config overrides
  let configOverrides: ConfigOverride[] = [];
  try {
    configOverrides = await db.getAll('configOverrides');
  } catch {
    // Config overrides store may not be populated
  }

  return { atoms, compositions, snapshots, voiceNotes, configOverrides };
}

/**
 * Mark all items as synced in IndexedDB after successful backup.
 */
async function markAsSynced(): Promise<void> {
  const db = await getDB();

  // Mark compositions as synced
  try {
    const tx = db.transaction('compositions', 'readwrite');
    const compositions = await tx.store.getAll();
    for (const comp of compositions) {
      if (!comp.synced) {
        comp.synced = true;
        await tx.store.put(comp);
      }
    }
    await tx.done;
  } catch { /* ignore */ }

  // Mark snapshots as synced
  try {
    const tx = db.transaction('snapshots', 'readwrite');
    const snapshots = await tx.store.getAll();
    for (const snap of snapshots) {
      if (!snap.synced) {
        snap.synced = true;
        await tx.store.put(snap);
      }
    }
    await tx.done;
  } catch { /* ignore */ }
}

/**
 * Fetch with exponential backoff retry.
 */
async function fetchWithRetry(
  url: string,
  options: RequestInit,
  attempt = 1,
): Promise<Response> {
  try {
    const res = await fetch(url, options);
    if (res.ok) return res;

    // Server error (5xx): retry
    if (res.status >= 500 && attempt < MAX_RETRIES) {
      const delay = RETRY_BASE_MS * Math.pow(2, attempt - 1);
      console.log(`[backup] Retry ${attempt}/${MAX_RETRIES} in ${delay}ms`);
      await new Promise(resolve => setTimeout(resolve, delay));
      return fetchWithRetry(url, options, attempt + 1);
    }

    return res; // Client error or max retries reached
  } catch (err) {
    if (attempt < MAX_RETRIES) {
      const delay = RETRY_BASE_MS * Math.pow(2, attempt - 1);
      console.log(`[backup] Retry ${attempt}/${MAX_RETRIES} in ${delay}ms (network error)`);
      await new Promise(resolve => setTimeout(resolve, delay));
      return fetchWithRetry(url, options, attempt + 1);
    }
    throw err;
  }
}

/**
 * Dispatch backup status event for UI binding.
 */
function dispatchStatusEvent(): void {
  window.dispatchEvent(new CustomEvent('eoe:backup-status', {
    detail: {
      status: currentStatus,
      lastBackupTime,
      lastError,
    },
  }));
}
```

Key design decisions:
- sendBeacon for auto-backup on close (survives page navigation on mobile)
- visibilitychange event (more reliable than beforeunload on mobile)
- Voice note audio blobs excluded (too large; metadata preserved)
- 3 retries with exponential backoff (1s, 2s, 4s)
- markAsSynced updates IndexedDB after successful backup
- Custom event dispatching for UI binding
  </action>
  <verify>
1. portfolio/src/scripts/backup-client.ts exists
2. createBackup() collects data from IndexedDB and POSTs to /api/backup
3. listBackups() returns array of BackupSummary from server
4. restoreFromBackup() downloads data and writes to IndexedDB
5. Auto-backup triggers on visibilitychange (hidden) and beforeunload
6. sendBeacon used for reliability on page close
7. Retry logic: 3 attempts with exponential backoff
8. markAsSynced updates synced flags after successful backup
9. `cd portfolio && npm run build` succeeds
  </verify>
  <done>
Backup client created with full backup/restore cycle, auto-backup on app close via sendBeacon, exponential backoff retry (3 attempts), selective restore, synced flag management, and status event dispatching for UI.
  </done>
</task>

<task type="auto">
  <name>Task 4: Enable sync status indicator and auto-backup</name>
  <files>
    portfolio/src/components/OfflineIndicator.astro
  </files>
  <action>
Enable the Phase 6 sync status feature flag and integrate auto-backup initialization.

**Update portfolio/src/components/OfflineIndicator.astro:**

1. Change the feature flag from false to true:

```typescript
const SHOW_SYNC_STATUS = true; // Phase 6: enabled
```

2. Update the checkSyncStatus function to also include snapshots in the unsynced count and show backup status:

Replace the existing `checkSyncStatus` function with an enhanced version:

```typescript
async function checkSyncStatus() {
  try {
    const { getUnsyncedCount } = await import('../scripts/composition-store');
    const compCount = await getUnsyncedCount();

    // Also check unsynced snapshots
    let snapCount = 0;
    try {
      const { getUnsyncedSnapshots } = await import('../scripts/db');
      const unsynced = await getUnsyncedSnapshots();
      snapCount = unsynced.length;
    } catch { /* snapshots store may not exist */ }

    const totalUnsynced = compCount + snapCount;
    const syncEl = document.getElementById('sync-status');
    const syncText = syncEl?.querySelector('.sync-text');
    const syncDot = syncEl?.querySelector('.sync-dot') as HTMLElement;

    if (syncEl && syncText) {
      if (totalUnsynced > 0) {
        syncText.textContent = `${totalUnsynced} item${totalUnsynced !== 1 ? 's' : ''} not backed up`;
        if (syncDot) syncDot.style.background = '#ffb56b'; // Orange: pending
        syncEl.style.display = 'flex';
      } else {
        syncText.textContent = 'All backed up';
        if (syncDot) syncDot.style.background = '#6bff6b'; // Green: synced
        syncEl.style.display = 'flex';
        // Hide after 3 seconds when fully synced
        setTimeout(() => {
          if (syncEl) syncEl.style.display = 'none';
        }, 3000);
      }
    }
  } catch {
    // Stores may not be initialized yet
  }
}
```

3. Add auto-backup initialization after the sync status setup:

```typescript
// Initialize auto-backup (Phase 6)
if (SHOW_SYNC_STATUS) {
  // ... existing periodic check code ...

  // Enable auto-backup on app close
  import('../scripts/backup-client').then(({ enableAutoBackup }) => {
    enableAutoBackup();
    console.log('[sync] Auto-backup enabled');
  }).catch(() => {
    // Module not available yet
  });

  // Listen for backup status changes
  window.addEventListener('eoe:backup-status', ((e: CustomEvent) => {
    const syncEl = document.getElementById('sync-status');
    const syncText = syncEl?.querySelector('.sync-text');
    const syncDot = syncEl?.querySelector('.sync-dot') as HTMLElement;

    if (!syncEl || !syncText) return;

    const { status, lastBackupTime } = e.detail;

    switch (status) {
      case 'backing-up':
        syncText.textContent = 'Backing up...';
        if (syncDot) syncDot.style.background = '#6bb5ff'; // Blue: active
        syncEl.style.display = 'flex';
        break;
      case 'success':
        syncText.textContent = 'Backup complete';
        if (syncDot) syncDot.style.background = '#6bff6b'; // Green
        syncEl.style.display = 'flex';
        setTimeout(() => { syncEl.style.display = 'none'; }, 3000);
        break;
      case 'error':
        syncText.textContent = 'Backup failed';
        if (syncDot) syncDot.style.background = '#ff6b6b'; // Red
        syncEl.style.display = 'flex';
        break;
    }
  }) as EventListener);
}
```

Update the sync-status CSS to add animation for the backing-up state:

```css
.sync-status {
  /* existing styles ... */
  transition: opacity 0.3s ease;
}

.sync-dot {
  /* existing styles ... */
  transition: background 0.3s ease;
}
```

Also add a pulsing animation for the active backup state:

```css
@keyframes sync-pulse {
  0%, 100% { opacity: 0.6; }
  50% { opacity: 1; }
}

.sync-dot.active {
  animation: sync-pulse 1.5s ease-in-out infinite;
}
```
  </action>
  <verify>
1. SHOW_SYNC_STATUS is set to true
2. Sync status shows unsynced count (compositions + snapshots)
3. Auto-backup enabled via enableAutoBackup() on page load
4. Backup status events update the sync indicator (blue=active, green=synced, red=error, orange=pending)
5. Fully synced message auto-hides after 3 seconds
6. `cd portfolio && npm run build` succeeds
7. No errors when backup server is unreachable (graceful degradation)
  </verify>
  <done>
Sync status indicator enabled (Phase 6 feature flag flipped). Shows unsynced count for compositions + snapshots. Auto-backup initialized on page load. Backup status events update indicator color (blue/green/red/orange). Graceful degradation when server unreachable.
  </done>
</task>

<task type="auto">
  <name>Task 5: Install server dependencies and verify build</name>
  <files>
    server/package.json
    deploy.sh
  </files>
  <action>
Install server dependencies and update the deploy script.

**Install server dependencies:**

```bash
cd server && npm install
```

This generates server/package-lock.json which is needed for the Docker build.

**Update deploy.sh** to handle the server directory in rsync:

The existing deploy.sh excludes certain directories. The server/ directory should be included. Verify the rsync command includes server/. The current rsync copies everything except the explicitly excluded dirs, so server/ is already included.

However, the deploy.sh currently runs `docker compose` only in portfolio/. Update it to handle the new multi-service compose:

```bash
#!/bin/bash
set -euo pipefail

REMOTE="root@fra"
REMOTE_DIR="/opt/eoe-portfolio"

echo "==> Syncing code to $REMOTE:$REMOTE_DIR..."
rsync -az --delete \
  --exclude=node_modules \
  --exclude=.git \
  --exclude=dist \
  --exclude=videos \
  --exclude=games \
  --exclude=devvit \
  --exclude=.vercel \
  --exclude=.planning \
  --exclude='.env' \
  -e ssh \
  ./ "$REMOTE:$REMOTE_DIR/"

echo "==> Building and starting containers on remote..."
ssh "$REMOTE" "cd $REMOTE_DIR/portfolio && docker compose down --remove-orphans 2>/dev/null; docker compose up -d --build"

echo "==> Waiting for containers health..."
ssh "$REMOTE" "sleep 5 && docker ps --filter name=eoe --format '{{.Names}}: {{.Status}}'"

echo "==> Testing portfolio response..."
ssh "$REMOTE" "curl -s -o /dev/null -w '%{http_code}' http://localhost:3080/"

echo "==> Testing backup server..."
ssh "$REMOTE" "curl -s -o /dev/null -w '%{http_code}' http://localhost:3081/api/health"

echo ""
echo "Deploy complete! Site should be at https://llm.sutyrin.pro"
```

Key changes:
- Updated description of what's built ("containers" plural)
- Added health check for backup server
- Increased sleep to 5s for both containers to start
- Show status of all eoe containers

**Verify the full build:**

```bash
cd portfolio && npm run build
```

This ensures the portfolio (which now imports backup-client.ts) builds successfully.
  </action>
  <verify>
1. server/package-lock.json exists (generated by npm install)
2. deploy.sh tests both portfolio and backup server health
3. `cd portfolio && npm run build` succeeds with backup-client.ts imports
4. docker-compose.yml validates: `cd portfolio && docker compose config`
5. No regressions in existing build or functionality
  </verify>
  <done>
Server dependencies installed, deploy script updated for multi-container deployment with backup server health check. Portfolio build verified with backup-client.ts integration. Docker compose validates with both services.
  </done>
</task>

</tasks>

<verification>
1. `cd portfolio && npm run build` completes without errors
2. server/backup-server.js has all endpoints: POST backup, GET latest, GET list, POST restore, DELETE
3. server/Dockerfile builds and exposes port 3081
4. docker-compose.yml has eoe-portfolio and eoe-backup services
5. nginx.conf proxies /api/ to eoe-backup:3081
6. backup-client.ts createBackup() collects all IndexedDB data and uploads
7. Auto-backup fires on visibilitychange (hidden) via sendBeacon
8. Retry logic: 3 attempts with exponential backoff (1s, 2s, 4s)
9. restoreFromBackup supports selective restore (atoms, compositions, snapshots)
10. Sync status indicator shows unsynced count and backup progress
11. SHOW_SYNC_STATUS = true (feature flag enabled)
12. Cloud backup completes in <30 seconds (target from ROADMAP)
13. No storage limits enforced (user manages)
14. All backups kept indefinitely
15. Deploy script tests both services
</verification>

<success_criteria>
- SYNC-01: User can backup atoms, compositions, snapshots to cloud
- SYNC-02: User can see backup status (indicator in header area)
- Auto-backup on app close (visibilitychange + sendBeacon)
- Auto-retry on failure (3 attempts, exponential backoff)
- Selective restore supported (user picks categories)
- No storage limits, indefinite retention
- Server persists data across container restarts (Docker volume)
- Foundation for conflict resolution (Plan 06-04) and shareable URLs (Plan 06-05)
</success_criteria>

<output>
After completion, create `.planning/phases/06-composition-preview-save-cloud-backup/06-03-SUMMARY.md`
</output>
