---
phase: 03-video-capture-distribution
plan: 01
type: execute
wave: 1
depends_on: ["02-03"]
files_modified:
  - package.json
  - cli/package.json
  - cli/index.js
  - cli/commands/capture.js
  - cli/lib/resolve-atom.js
  - lib/capture/browser-capture.js
  - lib/capture/media-recorder-inject.js
  - lib/capture/audio-capture.js
  - lib/capture/index.js
autonomous: true

must_haves:
  truths:
    - "User can run `eoe capture <atom>` and get a master WebM video file in videos/masters/"
    - "Capture works for all atom types: visual, audio, audio-visual, composition"
    - "Default capture duration is 10 seconds, overridable with `--duration <seconds>`"
    - "Canvas stream captured at 30 FPS via canvas.captureStream(30)"
    - "Audio atoms captured with Tone.js output via MediaStreamAudioDestinationNode"
    - "Visual-only atoms produce video without audio track"
    - "Playwright launches headless Chromium, navigates to atom, injects MediaRecorder capture script"
    - "Audio atoms auto-click Play button to start audio before capture begins"
    - "Captured video saved as WebM VP9+Opus (master quality) in videos/masters/<atom-name>.webm"
    - "Capture command reports file size and duration on completion"
  artifacts:
    - path: "cli/commands/capture.js"
      provides: "CLI command: eoe capture <atom> --duration 10"
      contains: "captureCommand"
    - path: "lib/capture/browser-capture.js"
      provides: "Playwright browser automation for atom capture"
      contains: "captureAtom"
    - path: "lib/capture/media-recorder-inject.js"
      provides: "MediaRecorder injection script for in-browser recording"
      contains: "captureStream"
    - path: "lib/capture/audio-capture.js"
      provides: "Audio stream combination logic for Tone.js capture"
      contains: "audioDestination"
    - path: "lib/capture/index.js"
      provides: "Barrel export for capture library"
      contains: "captureAtom"
  key_links:
    - from: "cli/commands/capture.js"
      to: "lib/capture/browser-capture.js"
      via: "import captureAtom"
      pattern: "import.*capture"
    - from: "cli/commands/capture.js"
      to: "cli/lib/resolve-atom.js"
      via: "import resolveAtomPath"
      pattern: "import.*resolve"
    - from: "lib/capture/browser-capture.js"
      to: "lib/capture/media-recorder-inject.js"
      via: "page.evaluate injection"
      pattern: "evaluate"
    - from: "lib/capture/browser-capture.js"
      to: "lib/capture/audio-capture.js"
      via: "audio stream setup within injection"
      pattern: "audioDestination"
---

<objective>
Create the video capture pipeline that records running atoms (visual + audio) to master WebM files. After this plan, users can run `eoe capture <atom>` to launch a headless browser, record the canvas with optional audio for 10 seconds (configurable), and save a master-quality WebM file.

Purpose: This is the foundational capture step required before any encoding, thumbnailing, or publishing can happen. Without a reliable master recording, the entire Phase 3 pipeline has no input. The master WebM preserves maximum quality for downstream encoding.
Output: Working `eoe capture` CLI command, Playwright-based browser automation, MediaRecorder injection for canvas+audio capture, master WebM files in videos/masters/.
</objective>

<execution_context>
@/home/pavel/.claude/get-shit-done/workflows/execute-plan.md
@/home/pavel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-video-capture-distribution/03-CONTEXT.md
@.planning/phases/03-video-capture-distribution/03-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Playwright and create capture library</name>
  <files>
    package.json
    lib/capture/browser-capture.js
    lib/capture/media-recorder-inject.js
    lib/capture/audio-capture.js
    lib/capture/index.js
  </files>
  <action>
Install Playwright as a root dev dependency for headless browser automation. Also ensure ffmpeg-static is installed for later use (Plan 03-02 needs it but installing now avoids a second install cycle).

**Update root package.json devDependencies:**
```json
"devDependencies": {
  "vite": "^7.3.1",
  "eslint": "^9.0.0",
  "prettier": "^3.0.0",
  "playwright": "^1.50.0"
}
```

Run `npm install` then `npx playwright install chromium` to download the Chromium browser binary.

**Create lib/capture/media-recorder-inject.js** -- The script injected into the browser page to perform the actual recording. This runs in the browser context, not Node.js. Export it as a string or function that will be passed to `page.evaluate()`.

```javascript
/**
 * MediaRecorder injection script for in-browser canvas + audio recording.
 * This function runs inside the Playwright browser page context.
 * It captures the canvas stream, optionally combines with Tone.js audio,
 * and returns the recorded video as a base64-encoded WebM.
 *
 * @param {object} options
 * @param {number} options.duration - Capture duration in milliseconds
 * @param {number} options.fps - Frame rate for canvas capture
 * @param {boolean} options.hasAudio - Whether to capture audio stream
 * @returns {string} Base64-encoded WebM video data
 */
export function getMediaRecorderScript() {
  // Return the function body as a serializable function for page.evaluate
  return async function captureInBrowser({ duration, fps, hasAudio }) {
    // Wait for canvas to be ready
    let canvas = document.querySelector('canvas');
    let attempts = 0;
    while (!canvas && attempts < 50) {
      await new Promise(r => setTimeout(r, 100));
      canvas = document.querySelector('canvas');
      attempts++;
    }

    if (!canvas) {
      throw new Error('No canvas element found on page');
    }

    // Get canvas video stream
    const videoStream = canvas.captureStream(fps);
    let combinedStream;

    if (hasAudio && typeof Tone !== 'undefined') {
      // Access Tone.js audio context and create a destination for recording
      const audioContext = Tone.context.rawContext || Tone.context._context;
      const audioDestination = audioContext.createMediaStreamDestination();

      // Connect Tone.js master output to our recording destination
      // Tone.Destination is the master output node
      Tone.getDestination().connect(audioDestination);

      // Combine video and audio tracks
      combinedStream = new MediaStream([
        ...videoStream.getVideoTracks(),
        ...audioDestination.stream.getAudioTracks()
      ]);
    } else {
      combinedStream = videoStream;
    }

    // Determine supported MIME type
    let mimeType = 'video/webm;codecs=vp9,opus';
    if (!MediaRecorder.isTypeSupported(mimeType)) {
      mimeType = 'video/webm;codecs=vp8,opus';
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'video/webm';
      }
    }

    // Create MediaRecorder
    const mediaRecorder = new MediaRecorder(combinedStream, {
      mimeType,
      videoBitsPerSecond: 8000000 // 8 Mbps for high quality master
    });

    const chunks = [];
    mediaRecorder.ondataavailable = (e) => {
      if (e.data.size > 0) chunks.push(e.data);
    };

    // Record
    return new Promise((resolve, reject) => {
      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'video/webm' });
        // Convert to base64 for transfer back to Node.js
        const reader = new FileReader();
        reader.onloadend = () => resolve(reader.result);
        reader.onerror = () => reject(new Error('Failed to read video blob'));
        reader.readAsDataURL(blob);
      };

      mediaRecorder.onerror = (e) => reject(new Error(`MediaRecorder error: ${e.error?.message || 'unknown'}`));

      // Request data every second for progress
      mediaRecorder.start(1000);

      setTimeout(() => {
        mediaRecorder.stop();
      }, duration);
    });
  };
}
```

**Create lib/capture/audio-capture.js** -- Utilities for detecting and handling audio in atoms:

```javascript
import fs from 'fs-extra';
import path from 'path';

/**
 * Detect whether an atom has audio capabilities by examining its files.
 * Audio atoms have: audio.js, composition.js, or config.json with type audio/audio-visual/composition.
 *
 * @param {string} atomPath - Full path to atom directory
 * @returns {Promise<boolean>} True if atom has audio
 */
export async function detectAudioAtom(atomPath) {
  // Check config.json for type
  const configPath = path.join(atomPath, 'config.json');
  if (await fs.pathExists(configPath)) {
    try {
      const config = await fs.readJson(configPath);
      const audioTypes = ['audio', 'audio-visual', 'composition'];
      if (audioTypes.includes(config.type)) {
        return true;
      }
    } catch (e) {
      // Config parse failed, fall through to file detection
    }
  }

  // Check for audio-related files
  const audioFiles = ['audio.js', 'composition.js'];
  for (const file of audioFiles) {
    if (await fs.pathExists(path.join(atomPath, file))) {
      return true;
    }
  }

  return false;
}

/**
 * Determine the method to start audio playback in the browser.
 * Audio/audio-visual/composition atoms have a Play button that needs clicking.
 *
 * @param {string} atomPath - Full path to atom directory
 * @returns {Promise<string|null>} CSS selector for play button, or null if no audio
 */
export async function getPlayButtonSelector(atomPath) {
  const hasAudio = await detectAudioAtom(atomPath);
  if (!hasAudio) return null;

  // All audio templates use #playBtn
  return '#playBtn';
}
```

**Create lib/capture/browser-capture.js** -- Main Playwright capture orchestration:

```javascript
import { chromium } from 'playwright';
import path from 'path';
import fs from 'fs-extra';
import { getMediaRecorderScript } from './media-recorder-inject.js';
import { detectAudioAtom, getPlayButtonSelector } from './audio-capture.js';

/**
 * Capture a running atom to a WebM video file using Playwright + MediaRecorder.
 *
 * Flow:
 * 1. Start Vite dev server for the atom (or use file:// URL)
 * 2. Launch headless Chromium with GPU flags
 * 3. Navigate to atom page
 * 4. If audio atom: click Play button to start audio
 * 5. Inject MediaRecorder script to capture canvas + audio
 * 6. Wait for capture duration
 * 7. Save WebM file to videos/masters/
 *
 * @param {object} options
 * @param {string} options.atomPath - Full path to atom directory
 * @param {string} options.atomName - Atom folder name (e.g., "2026-01-30-my-sketch")
 * @param {number} options.duration - Capture duration in seconds (default: 10)
 * @param {number} options.fps - Frame rate (default: 30)
 * @param {string} options.outputDir - Output directory (default: videos/masters)
 * @returns {Promise<{outputPath: string, fileSize: number, duration: number}>}
 */
export async function captureAtom(options) {
  const {
    atomPath,
    atomName,
    duration = 10,
    fps = 30,
    outputDir = path.resolve('videos', 'masters')
  } = options;

  // Ensure output directory exists
  await fs.ensureDir(outputDir);

  const outputPath = path.join(outputDir, `${atomName}.webm`);
  const hasAudio = await detectAudioAtom(atomPath);
  const playSelector = await getPlayButtonSelector(atomPath);
  const durationMs = duration * 1000;

  // Start a temporary Vite dev server for the atom
  // We use dynamic import to avoid requiring vite as a direct dependency
  const { createServer } = await import('vite');
  const viteServer = await createServer({
    root: path.resolve('.'),
    server: { port: 0 }, // Auto-assign port
    logLevel: 'silent'
  });
  await viteServer.listen();
  const port = viteServer.config.server.port || viteServer.httpServer.address().port;
  const atomUrl = `http://localhost:${port}/atoms/${atomName}/index.html`;

  let browser;
  try {
    // Launch browser with GPU acceleration for canvas rendering
    browser = await chromium.launch({
      headless: true,
      args: [
        '--use-angle=gl',
        '--enable-gpu',
        '--enable-webgl',
        '--autoplay-policy=no-user-gesture-required', // Allow audio autoplay
        '--disable-web-security' // Allow file access if needed
      ]
    });

    const context = await browser.newContext({
      viewport: { width: 800, height: 800 },
      // Grant permissions for audio
      permissions: ['camera', 'microphone']
    });

    const page = await context.newPage();

    // Navigate to atom
    await page.goto(atomUrl, { waitUntil: 'networkidle' });

    // Wait for canvas to render
    await page.waitForSelector('canvas', { timeout: 10000 });

    // Additional wait for initialization (p5.js setup, Tone.js load)
    await page.waitForTimeout(1000);

    // If audio atom, click Play to start audio
    if (playSelector) {
      const playBtn = await page.$(playSelector);
      if (playBtn) {
        await playBtn.click();
        // Wait for audio to initialize
        await page.waitForTimeout(500);
      }
    }

    // Inject and run MediaRecorder capture
    const captureScript = getMediaRecorderScript();
    const base64Video = await page.evaluate(captureScript, {
      duration: durationMs,
      fps,
      hasAudio
    });

    // Convert base64 data URL to buffer and save
    const base64Data = base64Video.split(',')[1];
    const videoBuffer = Buffer.from(base64Data, 'base64');
    await fs.writeFile(outputPath, videoBuffer);

    const fileSize = videoBuffer.length;

    return {
      outputPath,
      fileSize,
      duration
    };

  } finally {
    if (browser) await browser.close();
    await viteServer.close();
  }
}
```

**Create lib/capture/index.js** -- Barrel export:

```javascript
export { captureAtom } from './browser-capture.js';
export { detectAudioAtom, getPlayButtonSelector } from './audio-capture.js';
export { getMediaRecorderScript } from './media-recorder-inject.js';
```

After creating all files, run `npm install && npx playwright install chromium`.
  </action>
  <verify>
1. `npm install` completes without errors
2. `npx playwright install chromium` downloads Chromium successfully
3. All lib/capture/ files exist: browser-capture.js, media-recorder-inject.js, audio-capture.js, index.js
4. `node -e "import('./lib/capture/audio-capture.js').then(m => console.log(Object.keys(m)))"` prints exports
5. `node -e "import('./lib/capture/media-recorder-inject.js').then(m => console.log(typeof m.getMediaRecorderScript))"` prints 'function'
  </verify>
  <done>
Playwright installed with Chromium browser. Capture library created at lib/capture/ with browser automation (Playwright launch, navigate, wait for canvas), MediaRecorder injection script (canvas.captureStream + Tone.js audio combination), audio detection utility (reads config.json type or checks for audio files), and barrel export. Temporary Vite dev server used for serving atoms during capture.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create `eoe capture` CLI command</name>
  <files>
    cli/commands/capture.js
    cli/index.js
    cli/lib/resolve-atom.js
  </files>
  <action>
Create the `eoe capture` CLI command that ties the capture library into the existing CLI framework.

**Create cli/commands/capture.js:**

```javascript
import { Command } from 'commander';
import path from 'path';
import chalk from 'chalk';
import { resolveAtomPath } from '../lib/resolve-atom.js';

export const captureCommand = new Command('capture')
  .argument('<atom>', 'Atom name to capture (e.g., my-first-sketch or 2026-01-30-my-first-sketch)')
  .option('-d, --duration <seconds>', 'Capture duration in seconds', '10')
  .option('--fps <rate>', 'Frame rate for capture', '30')
  .option('-o, --output <dir>', 'Output directory for master video', 'videos/masters')
  .description('Record a running atom to video (canvas + audio)')
  .action(async (atomName, options) => {
    const result = await resolveAtomPath(atomName);

    if (result.error === 'not_found') {
      console.error(chalk.red(`Atom "${atomName}" not found in atoms/`));
      console.error(chalk.gray('Run `eoe list` to see available atoms'));
      process.exit(1);
    }

    if (result.error === 'ambiguous') {
      console.error(chalk.red(`Multiple atoms match "${atomName}":`));
      result.matches.forEach(match => console.error(chalk.gray(`  ${match}`)));
      console.error(chalk.gray('Use the full name to disambiguate.'));
      process.exit(1);
    }

    const atomPath = result.path;
    const resolvedName = result.name;
    const duration = parseInt(options.duration, 10);
    const fps = parseInt(options.fps, 10);
    const outputDir = path.resolve(options.output);

    // Validate duration
    if (isNaN(duration) || duration < 1 || duration > 120) {
      console.error(chalk.red('Duration must be between 1 and 120 seconds'));
      process.exit(1);
    }

    // Validate fps
    if (isNaN(fps) || fps < 15 || fps > 60) {
      console.error(chalk.red('FPS must be between 15 and 60'));
      process.exit(1);
    }

    // Detect audio
    const { detectAudioAtom } = await import('../../lib/capture/audio-capture.js');
    const hasAudio = await detectAudioAtom(atomPath);

    console.log(chalk.blue(`Capturing ${resolvedName}...`));
    console.log(chalk.gray(`  Duration: ${duration}s`));
    console.log(chalk.gray(`  FPS: ${fps}`));
    console.log(chalk.gray(`  Audio: ${hasAudio ? 'yes' : 'no'}`));
    console.log(chalk.gray(`  Output: ${outputDir}/`));
    console.log();

    try {
      const { captureAtom } = await import('../../lib/capture/browser-capture.js');

      const startTime = Date.now();
      const result = await captureAtom({
        atomPath,
        atomName: resolvedName,
        duration,
        fps,
        outputDir
      });

      const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
      const sizeMB = (result.fileSize / (1024 * 1024)).toFixed(2);

      console.log(chalk.green(`\nCapture complete!`));
      console.log(chalk.gray(`  File: ${result.outputPath}`));
      console.log(chalk.gray(`  Size: ${sizeMB} MB`));
      console.log(chalk.gray(`  Duration: ${result.duration}s`));
      console.log(chalk.gray(`  Elapsed: ${elapsed}s`));
      console.log();
      console.log(chalk.gray(`  Next: eoe encode ${resolvedName}`));

    } catch (err) {
      console.error(chalk.red(`\nCapture failed: ${err.message}`));
      if (err.message.includes('No canvas element')) {
        console.error(chalk.gray('The atom must have a <canvas> element to capture.'));
      }
      if (err.message.includes('chromium')) {
        console.error(chalk.gray('Run `npx playwright install chromium` to install the browser.'));
      }
      process.exit(1);
    }
  });
```

**Update cli/index.js** -- Register the capture command:

Add to the imports at the top:
```javascript
import { captureCommand } from './commands/capture.js';
```

Add to the program commands (after buildCommand):
```javascript
program.addCommand(captureCommand);
```

The resolve-atom.js utility already handles atom name resolution. No changes needed there -- it already supports both short names and full date-prefixed names.
  </action>
  <verify>
1. `eoe capture --help` shows usage with --duration and --fps options
2. `eoe capture nonexistent` shows "not found" error with suggestion to run `eoe list`
3. `eoe capture my-first-sketch` resolves atom name and begins capture
4. Capture completes with file in videos/masters/<atom-name>.webm
5. File size and duration reported on completion
6. `eoe capture my-first-sketch --duration 5` captures for 5 seconds
7. `eoe capture my-first-sketch --duration 0` shows validation error
8. `eoe capture my-first-sketch --duration 200` shows validation error (max 120s)
  </verify>
  <done>
CLI capture command created at cli/commands/capture.js with --duration (1-120s, default 10) and --fps (15-60, default 30) options. Registered in cli/index.js. Command resolves atom names (supports short and full names), detects audio, reports capture progress, and outputs file location and size. Error handling covers missing atoms, missing canvas, and missing Playwright browser.
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify end-to-end capture workflow</name>
  <files>
    (no new files -- verification task)
  </files>
  <action>
Test the capture pipeline end-to-end with both visual-only and audio-enabled atoms.

**Visual Atom Capture Test:**
1. `eoe capture my-first-sketch` -- captures the existing visual atom
2. Verify output file exists: `ls -la videos/masters/2026-01-30-my-first-sketch.webm`
3. Verify file is valid WebM (non-zero size, playable)
4. Verify capture took approximately 10 seconds (plus overhead)

**Duration Override Test:**
5. `eoe capture my-first-sketch --duration 3` -- short capture
6. Verify file is smaller than the 10s capture

**Audio Atom Capture Test (if audio atoms exist):**
7. Create a test audio atom if none exist: `eoe create audio-visual capture-test`
8. `eoe capture capture-test`
9. Verify audio detection reported "Audio: yes"
10. Verify Play button was auto-clicked (no manual interaction needed)
11. Verify output contains both video and audio tracks (play it to confirm)

**Error Handling Tests:**
12. `eoe capture nonexistent-atom` -- verify clean error message
13. Test with an atom that has no canvas -- verify "No canvas element" error

**Output Directory Test:**
14. `eoe capture my-first-sketch -o ./test-output` -- verify custom output dir works
15. Clean up test files: `rm -rf ./test-output`

If headless rendering produces black frames or visual glitches, investigate the Playwright launch flags (--use-angle=gl, --enable-gpu). May need to add additional flags or increase initialization wait time.

If audio capture produces silent track, verify that the MediaStreamAudioDestinationNode connection to Tone.Destination works in the headless browser context. May need to adjust the audio routing in the injection script.

Clean up test atom and any test output after verification:
```bash
rm -rf atoms/YYYY-MM-DD-capture-test
```
  </action>
  <verify>
1. Visual atom captures to valid WebM file in videos/masters/
2. Capture duration approximately matches --duration flag
3. Audio atoms detect audio presence correctly
4. Audio atoms auto-click Play before capture
5. Custom output directory works
6. Error messages are clear and actionable
7. No orphan processes (Vite server, Chromium) after capture completes or fails
  </verify>
  <done>
End-to-end capture pipeline verified: visual atoms produce valid WebM video, audio atoms include audio track, duration flag controls recording length, custom output directories work, error handling is clean. Playwright and Vite server properly cleaned up on completion and failure.
  </done>
</task>

</tasks>

<verification>
1. `npm install` succeeds with Playwright added as dev dependency
2. `npx playwright install chromium` downloads browser successfully
3. `eoe capture <atom>` records running atom to WebM video
4. Default duration is 10 seconds, overridable with --duration
5. Canvas captured at 30 FPS via captureStream(30)
6. Audio atoms include Tone.js output in video
7. Visual-only atoms produce video without audio track
8. Play button auto-clicked for audio atoms
9. Output saved to videos/masters/<atom-name>.webm
10. File size and duration reported on completion
</verification>

<success_criteria>
- `eoe capture <atom>` produces a master WebM video in <15 seconds (for 10s capture) (VID-01, CLI-04)
- Visual atoms captured at 800x800 native resolution (no upscaling)
- Audio atoms captured with synchronized Tone.js output (VID-04)
- Canvas stream at 30 FPS using MediaRecorder API (VID-01)
- All 4 atom types supported: visual, audio, audio-visual, composition
- Headless Chromium launches with GPU flags for canvas rendering quality
- Temporary Vite server serves atom during capture, cleaned up after
- Videos saved as WebM VP9+Opus (master quality, 8 Mbps)
- Duration validation: 1-120 seconds, default 10
- Clean error handling for missing atoms, missing canvas, missing browser
</success_criteria>

<output>
After completion, create `.planning/phases/03-video-capture-distribution/03-01-SUMMARY.md`
</output>
